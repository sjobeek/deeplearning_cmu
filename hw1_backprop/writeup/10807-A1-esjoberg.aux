\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Overfitting and Model Complexity}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Typical Training Behavior: Error Rate vs Model Complexity}{1}{subsection.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Typical Training Behavior: Error Rate vs Training Set Size}{1}{subsection.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Expected Loss for Regression}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}a) Case q = 1}{2}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}b) Case q -> 0}{2}{subsection.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Binary Classification Error Function}{2}{section.3}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Generalized Gaussian}{2}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Show Distribution is Normalized}{2}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Derive Log-likelihood Function}{3}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Implementation of Backpropagation}{3}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}a) Basic Generalization}{3}{subsection.5.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training cross-entropy error (blue) and test cross-entropy error (red) for 5 seeds.}}{3}{figure.1}}
\newlabel{fig:crosen1}{{1}{3}{Training cross-entropy error (blue) and test cross-entropy error (red) for 5 seeds}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}b) Classification Error}{4}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Training classification error (blue) and test classification error (red) for 5 seeds.}}{4}{figure.2}}
\newlabel{fig:class1}{{2}{4}{Training classification error (blue) and test classification error (red) for 5 seeds}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}c) Visualizing Parameters}{4}{subsection.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}d) Learning Rate}{4}{subsection.5.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visualization of 10-by-10 grid of learned parameters from the bottom layer of the network.}}{5}{figure.3}}
\newlabel{fig:paramviz}{{3}{5}{Visualization of 10-by-10 grid of learned parameters from the bottom layer of the network}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualization of error rates with various learning rates. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively. }}{5}{figure.4}}
\newlabel{fig:learnrates}{{4}{5}{Visualization of error rates with various learning rates. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}e) Number of Hidden Units}{5}{subsection.5.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Visualization of error rates with various momentum values. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively. }}{6}{figure.5}}
\newlabel{fig:momentums}{{5}{6}{Visualization of error rates with various momentum values. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Visualization of error rates with various numbers of hidden layers. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively. }}{6}{figure.6}}
\newlabel{fig:hiddenunits}{{6}{6}{Visualization of error rates with various numbers of hidden layers. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}f) Dropout}{6}{subsection.5.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}g) Best-Performing Single Layer}{6}{subsection.5.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Visualization of error rates during training with dropout. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively. }}{7}{figure.7}}
\newlabel{fig:momentumsrate1}{{7}{7}{Visualization of error rates during training with dropout. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Visualization of error rates of standard single-layer a network trained with dropout. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively. }}{8}{figure.8}}
\newlabel{fig:dropout1}{{8}{8}{Visualization of error rates of standard single-layer a network trained with dropout. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Visualization of error rates of standard single-layer a network trained with dropout and three different numbers of hidden layers. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively. }}{8}{figure.9}}
\newlabel{fig:dropout1}{{9}{8}{Visualization of error rates of standard single-layer a network trained with dropout and three different numbers of hidden layers. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}h) Extension to Multiple Layers}{8}{subsection.5.8}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Visualization of VALIDATION error rates of the single-layer network with the best performance. Red and blue are cross-entropy error for validation and train, while green and black are categorization error for validation and train respectively. }}{9}{figure.10}}
\newlabel{fig:onelayerbest}{{10}{9}{Visualization of VALIDATION error rates of the single-layer network with the best performance. Red and blue are cross-entropy error for validation and train, while green and black are categorization error for validation and train respectively}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Best 1-layer features: visualization of 100 28x28 element top-level weights arranged in a grid. }}{9}{figure.11}}
\newlabel{fig:onelayerbestfeatures}{{11}{9}{Best 1-layer features: visualization of 100 28x28 element top-level weights arranged in a grid}{figure.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Visualization of error rates with various momentum values. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively. }}{10}{figure.12}}
\newlabel{fig:momentumsrate1}{{12}{10}{Visualization of error rates with various momentum values. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Visualization of error rates with various momentum values. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively. }}{10}{figure.13}}
\newlabel{fig:momentumsrate2}{{13}{10}{Visualization of error rates with various momentum values. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively}{figure.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Visualization of error rates with various momentum values. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively. }}{11}{figure.14}}
\newlabel{fig:momentumsrate3}{{14}{11}{Visualization of error rates with various momentum values. Red and blue are cross-entropy error for test and train, while green and black are categorization error for test and train respectively}{figure.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Visualization of VALIDATION error rates for the best two-layer network. Red and blue are cross-entropy error for test and validation, while green and black are categorization error for test and validation respectively. }}{11}{figure.15}}
\newlabel{fig:twolayerbest}{{15}{11}{Visualization of VALIDATION error rates for the best two-layer network. Red and blue are cross-entropy error for test and validation, while green and black are categorization error for test and validation respectively}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Best 2-layer features: visualization of 100 28x28 element top-level weights arranged in a grid. }}{11}{figure.16}}
\newlabel{fig:twolayerbestfeatures}{{16}{11}{Best 2-layer features: visualization of 100 28x28 element top-level weights arranged in a grid}{figure.16}{}}
